{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'experiment-output/ch6/ED_NB-G-F_GB2-G2-F2_L3_c0_s0_p0_smp15.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# args = json.load(open('config.json'))\u001b[39;00m\n\u001b[1;32m     76\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment-output/ch6/ED_NB-G-F_GB2-G2-F2_L3_c0_s0_p0_smp15.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 77\u001b[0m data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     79\u001b[0m indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(data\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run, (path, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment-output/ch5/plain-PDL/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746265816-296861\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     82\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment-output/ch5/repair-1/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746429988-424426\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     83\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment-output/ch5/repair-2/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746434902-974866\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     84\u001b[0m             [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepair1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepair2\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n",
      "File \u001b[0;32m~/miniconda3/envs/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'experiment-output/ch6/ED_NB-G-F_GB2-G2-F2_L3_c0_s0_p0_smp15.pkl'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('../..')\n",
    "from networks import DualNet, DualNetEndToEnd, PrimalNet, PrimalNetEndToEnd, PrimalNetEndToEnd\n",
    "import torch\n",
    "\n",
    "def evaluate(data, primal_net, test_indices):        \n",
    "    X = data.X[test_indices]\n",
    "    Y_target = data.opt_targets[\"y_operational\"][test_indices]\n",
    "    \n",
    "    # Forward pass through networks\n",
    "    Y = primal_net(X)\n",
    "\n",
    "    ineq_dist = data.ineq_dist(X, Y)\n",
    "    eq_resid = data.eq_resid(X, Y)\n",
    "\n",
    "    relative_ineq_dist = data.relative_ineq_dist(X, Y)\n",
    "    relative_eq_resid = data.relative_eq_resid(X, Y)\n",
    "\n",
    "    # Convert lists to arrays for easier handling\n",
    "    obj_values = data.obj_fn(X, Y).detach().numpy()\n",
    "    ineq_max_vals = torch.max(ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    ineq_mean_vals = torch.mean(ineq_dist, dim=1).detach().numpy()\n",
    "    eq_max_vals = torch.max(torch.abs(eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    eq_mean_vals = torch.mean(torch.abs(eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    relative_ineq_max_vals = torch.max(relative_ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    relative_ineq_mean_vals = torch.mean(relative_ineq_dist, dim=1).detach().numpy()\n",
    "    relative_eq_max_vals = torch.max(torch.abs(relative_eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    relative_eq_mean_vals = torch.mean(torch.abs(relative_eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    known_obj = data.obj_fn(X, Y_target).detach().numpy()\n",
    "    # obj_values is negative\n",
    "    opt_gap = (obj_values - known_obj)/np.abs(known_obj) * 100\n",
    "\n",
    "    return np.mean(obj_values), np.mean(known_obj), np.mean(opt_gap), np.mean(ineq_max_vals), np.mean(relative_ineq_max_vals), np.mean(ineq_mean_vals), np.mean(relative_ineq_mean_vals), np.mean(eq_max_vals), np.mean(relative_eq_max_vals), np.mean(eq_mean_vals), np.mean(relative_eq_mean_vals)\n",
    "\n",
    "def dual_evaluate(data, dual_net, test_indices):\n",
    "    X = data.X[test_indices]\n",
    "    # target_mu = data.mu[test_indices]\n",
    "    # target_lamb = data.lamb[test_indices]\n",
    "    target_mu = data.opt_targets[\"mu_operational\"][test_indices]  \n",
    "    target_lamb = data.opt_targets[\"lamb_operational\"][test_indices]\n",
    "    print(X.dtype)\n",
    "    print(dual_net.net[0].weight.dtype)\n",
    "\n",
    "    # Forward pass through networks\n",
    "    mu, lamb = dual_net(X)\n",
    "\n",
    "    obj_values = data.dual_obj_fn(X, mu, lamb).detach().numpy()\n",
    "    known_obj = data.dual_obj_fn(X, target_mu, target_lamb).detach().numpy()\n",
    "    # dual_ineq_dist = data.dual_ineq_dist(mu, lamb)\n",
    "    dual_ineq_resid = data.dual_ineq_resid(mu, lamb)\n",
    "    dual_ineq_dist = torch.clamp(dual_ineq_resid, 0)\n",
    "    dual_eq_resid = data.dual_eq_resid(mu, lamb)\n",
    "\n",
    "    opt_gap = (obj_values - known_obj)/np.abs(known_obj) * 100\n",
    "\n",
    "    ineq_max_vals = torch.max(dual_ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    eq_max_vals = torch.max(torch.abs(dual_eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    ineq_mean_vals = torch.mean(dual_ineq_dist, dim=1).detach().numpy()\n",
    "    eq_mean_vals = torch.mean(torch.abs(dual_eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    return np.mean(obj_values), np.mean(known_obj), np.mean(opt_gap), np.mean(ineq_max_vals), np.mean(ineq_mean_vals), np.mean(eq_max_vals), np.mean(eq_mean_vals)\n",
    "\n",
    "repeats = 5\n",
    "stats_dict = {}\n",
    "\n",
    "# args = json.load(open('config.json'))\n",
    "data_path = f\"experiment-output/ch6/ED_NB-G-F_GB2-G2-F2_L3_c0_s0_p0_smp15.pkl\"\n",
    "data = pickle.load(open(data_path, 'rb'))\n",
    "\n",
    "indices = torch.arange(data.X.shape[0])\n",
    "\n",
    "for run, (path, name) in enumerate(zip([\"experiment-output/ch5/plain-PDL/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746265816-296861\",\n",
    "             \"experiment-output/ch5/repair-1/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746429988-424426\",\n",
    "             \"experiment-output/ch5/repair-2/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746434902-974866\"],\n",
    "            [\"plain\", \"repair1\", \"repair2\"])):\n",
    "    stats_dict[name] = {\"predicted_obj\": [], \"known_obj\": [], \"opt_gap\": [], \"ineq_max\": [], \"ineq_mean\": [], \"eq_max\": [], \"eq_mean\": [], \"relative_ineq_max\": [], \"relative_ineq_mean\": [], \"relative_eq_max\": [], \"relative_eq_mean\": []}\n",
    "    with open(os.path.join(path, 'args.json'), 'r') as f:\n",
    "        args = json.load(f)\n",
    "    # Compute sizes for each set\n",
    "    train_size = int(args[\"train\"] * data.X.shape[0])\n",
    "    valid_size = int(args[\"valid\"] * data.X.shape[0])\n",
    "    # print(f\"Train size: {train_size}, Valid size: {valid_size}, Test size: {data.X.shape[0] - train_size - valid_size}\")\n",
    "\n",
    "\n",
    "    # Split the indices\n",
    "    train_indices = indices[:train_size]\n",
    "    valid_indices = indices[train_size:train_size+valid_size]\n",
    "    test_indices = indices[train_size+valid_size:]\n",
    "\n",
    "    for i, repeat in enumerate(range(repeats)):\n",
    "        \n",
    "        directory = os.path.join(path, f\"repeat:{repeat}\")\n",
    "        # directory = f\"experiment-output/ch5-reproduction-nonconvex/{experiment}/repeat:{repeat}\"\n",
    "        # dual_net = DualNet(args, data=data)\n",
    "        # dual_net.load_state_dict(torch.load(os.path.join(directory, 'dual_weights.pth'), weights_only=True))\n",
    "\n",
    "        primal_net = PrimalNetEndToEnd2(args, data=data)\n",
    "        primal_net.load_state_dict(torch.load(os.path.join(directory, 'primal_weights.pth'), weights_only=True))\n",
    "        # obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean = dual_evaluate(data, dual_net, test_indices)\n",
    "        obj_val, known_obj, opt_gap, ineq_max, relative_ineq_max, ineq_mean, relative_ineq_mean, eq_max, relative_eq_max, eq_mean, relative_eq_mean = evaluate(data, primal_net, test_indices)\n",
    "        stats_dict[name][\"predicted_obj\"].append(obj_val)\n",
    "        stats_dict[name][\"known_obj\"].append(known_obj)\n",
    "        stats_dict[name][\"opt_gap\"].append(opt_gap)\n",
    "        stats_dict[name][\"ineq_max\"].append(ineq_max)\n",
    "        stats_dict[name][\"ineq_mean\"].append(ineq_mean)\n",
    "        stats_dict[name][\"eq_max\"].append(eq_max)\n",
    "        stats_dict[name][\"eq_mean\"].append(eq_mean)\n",
    "        stats_dict[name][\"relative_ineq_max\"].append(relative_ineq_max)\n",
    "        stats_dict[name][\"relative_ineq_mean\"].append(relative_ineq_mean)\n",
    "        stats_dict[name][\"relative_eq_max\"].append(relative_eq_max)\n",
    "        stats_dict[name][\"relative_eq_mean\"].append(relative_eq_mean)\n",
    "\n",
    "\n",
    "stats_dict\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Objective Table\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "Experiment & Optimal Obj & Predicted Obj & OptGap (%) \\\\\n",
      "\\midrule\n",
      "plain & 29293.887 & 582586.024(2784.077) & 27271.364(168.671) \\\\\n",
      "repair1 & 29293.887 & 80987.094(3916.860) & 2567.187(204.781) \\\\\n",
      "repair2 & 29293.887 & 29310.046(5.399) & 0.705(0.209) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "% Regular Constraint Table\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Experiment & IneqMax & IneqMean & EqMax & EqMean \\\\\n",
      "\\midrule\n",
      "plain & 711.543(14.045) & 46.839(1.263) & 5267.664(13.714) & 3261.341(7.769) \\\\\n",
      "repair1 & 34.633(10.675) & 1.533(0.459) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "repair2 & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "% Relative Constraint Table\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Experiment & Relative IneqMax & Relative IneqMean & Relative EqMax & Relative EqMean \\\\\n",
      "\\midrule\n",
      "plain & 166.923(9.203) & 10.407(0.553) & 0.169(0.000) & 0.136(0.000) \\\\\n",
      "repair1 & 0.002(0.000) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "repair2 & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare separate dictionaries\n",
    "objective_summary = {\"Experiment\": [], \"Optimal Obj\": [], \"Predicted Obj\": [], \"OptGap (%)\": []}\n",
    "regular_summary = {\"Experiment\": [], \"IneqMax\": [], \"IneqMean\": [], \"EqMax\": [], \"EqMean\": []}\n",
    "relative_summary = {\"Experiment\": [], \"Relative IneqMax\": [], \"Relative IneqMean\": [], \"Relative EqMax\": [], \"Relative EqMean\": []}\n",
    "\n",
    "for experiment, metrics in stats_dict.items():\n",
    "    objective_summary[\"Experiment\"].append(experiment)\n",
    "    objective_summary[\"Optimal Obj\"].append(f\"{np.mean(metrics['known_obj']):.3f}\")\n",
    "    objective_summary[\"Predicted Obj\"].append(f\"{np.mean(metrics['predicted_obj']):.3f}({np.std(metrics['predicted_obj']):.3f})\")\n",
    "    objective_summary[\"OptGap (%)\"].append(f\"{np.mean(metrics['opt_gap']):.3f}({np.std(metrics['opt_gap']):.3f})\")\n",
    "\n",
    "    regular_summary[\"Experiment\"].append(experiment)\n",
    "    regular_summary[\"IneqMax\"].append(f\"{np.mean(metrics['ineq_max']):.3f}({np.std(metrics['ineq_max']):.3f})\")\n",
    "    regular_summary[\"IneqMean\"].append(f\"{np.mean(metrics['ineq_mean']):.3f}({np.std(metrics['ineq_mean']):.3f})\")\n",
    "    regular_summary[\"EqMax\"].append(f\"{np.mean(metrics['eq_max']):.3f}({np.std(metrics['eq_max']):.3f})\")\n",
    "    regular_summary[\"EqMean\"].append(f\"{np.mean(metrics['eq_mean']):.3f}({np.std(metrics['eq_mean']):.3f})\")\n",
    "\n",
    "    relative_summary[\"Experiment\"].append(experiment)\n",
    "    relative_summary[\"Relative IneqMax\"].append(f\"{np.mean(metrics['relative_ineq_max']):.3f}({np.std(metrics['relative_ineq_max']):.3f})\")\n",
    "    relative_summary[\"Relative IneqMean\"].append(f\"{np.mean(metrics['relative_ineq_mean']):.3f}({np.std(metrics['relative_ineq_mean']):.3f})\")\n",
    "    relative_summary[\"Relative EqMax\"].append(f\"{np.mean(metrics['relative_eq_max']):.3f}({np.std(metrics['relative_eq_max']):.3f})\")\n",
    "    relative_summary[\"Relative EqMean\"].append(f\"{np.mean(metrics['relative_eq_mean']):.3f}({np.std(metrics['relative_eq_mean']):.3f})\")\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_obj = pd.DataFrame(objective_summary)\n",
    "df_regular = pd.DataFrame(regular_summary)\n",
    "df_relative = pd.DataFrame(relative_summary)\n",
    "\n",
    "# Export LaTeX tables\n",
    "latex_obj = df_obj.to_latex(index=False, escape=False)\n",
    "latex_regular = df_regular.to_latex(index=False, escape=False)\n",
    "latex_relative = df_relative.to_latex(index=False, escape=False)\n",
    "\n",
    "# Print or write to file\n",
    "print(\"% Objective Table\")\n",
    "print(latex_obj)\n",
    "print(\"\\n% Regular Constraint Table\")\n",
    "print(latex_regular)\n",
    "print(\"\\n% Relative Constraint Table\")\n",
    "print(latex_relative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repeats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experiment \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     dual_stats_dict[experiment] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknown_obj\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopt_gap\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mineq_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mineq_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meq_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meq_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m repeat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mrepeats\u001b[49m):\n\u001b[1;32m      6\u001b[0m         directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment-output/ch4/ch4-reproduction/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/repeat:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepeat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m         data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/QP_data/QP_type:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_var:100_ineq:50_eq:50_num_samples:10000.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'repeats' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the quality of dual solutions:\n",
    "dual_stats_dict = {}\n",
    "for experiment in [\"simple\"]:\n",
    "    dual_stats_dict[experiment] = {\"obj\": [], \"known_obj\": [], \"opt_gap\": [], \"ineq_max\": [], \"ineq_mean\": [], \"eq_max\": [], \"eq_mean\": []}\n",
    "    for repeat in range(repeats):\n",
    "        directory = f\"experiment-output/ch4/ch4-reproduction/{experiment}/repeat:{repeat}\"\n",
    "        data_path = f\"data/QP_data/QP_type:{experiment}_var:100_ineq:50_eq:50_num_samples:10000.pkl\"\n",
    "\n",
    "        args = json.load(open('config.json'))\n",
    "        data = pickle.load(open(data_path, 'rb'))\n",
    "        dual_net = DualNet(args, data=data)\n",
    "        dual_net.load_state_dict(torch.load(os.path.join(directory, 'dual_weights.pth'), weights_only=True))\n",
    "\n",
    "        obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean = dual_evaluate(data, dual_net, data.test_indices)\n",
    "        dual_stats_dict[experiment][\"obj\"].append(obj_val)\n",
    "        dual_stats_dict[experiment][\"known_obj\"].append(known_obj)\n",
    "        dual_stats_dict[experiment][\"opt_gap\"].append(opt_gap)\n",
    "        dual_stats_dict[experiment][\"ineq_max\"].append(ineq_max)\n",
    "        dual_stats_dict[experiment][\"ineq_mean\"].append(ineq_mean)\n",
    "        dual_stats_dict[experiment][\"eq_max\"].append(eq_max)\n",
    "        dual_stats_dict[experiment][\"eq_mean\"].append(eq_mean)\n",
    "\n",
    "dual_stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Optimal Obj & Predicted Obj & OptGap (\\%) & IneqMax & IneqMean & EqMax & EqMean \\\\\n",
      "\\midrule\n",
      "-15.037 & -7.778e+03(6.240e+03) & -5.175e+04(4.162e+04) & 0.023(0.006) & 0.003(0.001) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare final summary for LaTeX export\n",
    "summary = {\n",
    "    \"Optimal Obj\": [],\n",
    "    \"Predicted Obj\": [],\n",
    "    \"OptGap (\\%)\": [],\n",
    "    \"IneqMax\": [],\n",
    "    \"IneqMean\": [],\n",
    "    \"EqMax\": [],\n",
    "    \"EqMean\": [],\n",
    "}\n",
    "\n",
    "for experiment, metrics in dual_stats_dict.items():\n",
    "    summary[\"Optimal Obj\"].append(f\"{np.mean(metrics['known_obj']):.3f}\")\n",
    "    summary[\"Predicted Obj\"].append(f\"{np.mean(metrics['obj']):.3e}({np.std(metrics['obj']):.3e})\")\n",
    "    summary[\"OptGap (\\%)\"].append(f\"{np.mean(metrics['opt_gap']):.3e}({np.std(metrics['opt_gap']):.3e})\")\n",
    "    summary[\"IneqMax\"].append(\n",
    "        f\"{np.mean(metrics['ineq_max']):.3f}({np.std(metrics['ineq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"IneqMean\"].append(\n",
    "        f\"{np.mean(metrics['ineq_mean']):.3f}({np.std(metrics['ineq_mean']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMax\"].append(\n",
    "        f\"{np.mean(metrics['eq_max']):.3f}({np.std(metrics['eq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMean\"].append(\n",
    "        f\"{np.mean(metrics['eq_mean']):.3f}({np.std(metrics['eq_mean']):.3f})\"\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "\n",
    "# For LaTeX export\n",
    "latex_table = df.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m      4\u001b[0m metric_names \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_obj\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknown_obj\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptimal\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meq_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEq. Mean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(metric_names\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m---> 15\u001b[0m problem_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mstats_dict\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     16\u001b[0m repeats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(stats_dict[problem_types[\u001b[38;5;241m0\u001b[39m]][metrics[\u001b[38;5;241m0\u001b[39m]]))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Prepare multi-indexed rows: (Repeat, Renamed Metric)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mapping of original metric keys to display names\n",
    "metric_names = {\n",
    "    'predicted_obj': 'Predicted',\n",
    "    'known_obj': 'Optimal',\n",
    "    'opt_gap': 'Gap (\\\\%)',\n",
    "    'ineq_max': 'Ineq. Max',\n",
    "    'ineq_mean': 'Ineq. Mean',\n",
    "    'eq_max': 'Eq. Max',\n",
    "    'eq_mean': 'Eq. Mean'\n",
    "}\n",
    "\n",
    "metrics = list(metric_names.keys())\n",
    "problem_types = list(stats_dict.keys())\n",
    "repeats = range(len(stats_dict[problem_types[0]][metrics[0]]))\n",
    "\n",
    "# Prepare multi-indexed rows: (Repeat, Renamed Metric)\n",
    "rows = []\n",
    "for r in repeats:\n",
    "    for m in metrics:\n",
    "        rows.append((f\"Repeat {r}\", metric_names[m]))\n",
    "\n",
    "# Create DataFrame with multi-index rows and problem type columns\n",
    "df = pd.DataFrame(index=pd.MultiIndex.from_tuples(rows, names=[\"Repeat\", \"Metric\"]),\n",
    "                  columns=problem_types)\n",
    "\n",
    "# Fill in the values\n",
    "for problem in problem_types:\n",
    "    for r in repeats:\n",
    "        for m in metrics:\n",
    "            df.loc[(f\"Repeat {r}\", metric_names[m]), problem] = stats_dict[problem][m][r]\n",
    "\n",
    "# Convert to LaTeX with booktabs\n",
    "latex_table = df.to_latex(\n",
    "    escape=False,\n",
    "    multirow=True,\n",
    "    column_format='ll' + 'c' * len(problem_types),\n",
    "    bold_rows=False,\n",
    "    index_names=True,\n",
    "    header=True,\n",
    "    float_format=\"%.3f\",\n",
    "    caption=\"Detailed evaluation metrics per repeat and problem type.\",\n",
    "    label=\"tab:detailed-results\",\n",
    "    longtable=False,\n",
    "    na_rep=''\n",
    ")\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED_NB-G-F_GB2-G2-F2_L3_c0_s0_p0_smp15.pkl\n",
      "\u001b[34mplain-PDL\u001b[m\u001b[m\n",
      "\u001b[34mrepair-1\u001b[m\u001b[m\n",
      "\u001b[34mrepair-2\u001b[m\u001b[m\n",
      "solution_analysis.ipynb\n",
      "tables.ipynb\n",
      "tensorboard_plots.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gep_problem_operational.GEPOperationalProblemSet object at 0x108c02c40>\n"
     ]
    }
   ],
   "source": [
    "data_path = f\"ED_NB-G-F_GB2-G2-F2_L3_c0_s0_p0_smp15.pkl\"\n",
    "data = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32768, 9])\n",
      "range(1, 8761)\n",
      "tensor([3155.5285, 1369.2450, 1467.8731,  ..., 2429.6445, 1942.3357,\n",
      "        2349.2205], dtype=torch.float64)\n",
      "Number of samples: 32768\n",
      "Per unit investment tensor([[693.8206,  29.0175,  93.0703, 502.7595, 408.4569, 367.3533],\n",
      "        [717.5849,  59.6154, 343.7348, 293.3847, 534.0417, 448.8720],\n",
      "        [999.5382, 787.4132, 431.7997, 422.8027, 380.7295,   4.2450],\n",
      "        ...,\n",
      "        [877.2337, 294.3558, 843.5970, 354.7130, 681.9613,  15.1868],\n",
      "        [101.2786, 799.3239,  11.1882, 245.6552, 825.4401, 470.7783],\n",
      "        [762.1953, 645.9160, 338.5291, 656.8327, 953.4864, 705.0021]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(data.X.shape)\n",
    "print(data.T)\n",
    "print(data.opt_targets['obj'])\n",
    "print(f\"Number of samples: {data.n_samples}\")\n",
    "print(f\"Per unit investment {data.pUnitInvestment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
